---
layout: post
title:  "Practical Data Mesh"
date:   2023-01-06 00:00:00 +0000
categories: datamesh
tags: datamesh
---

![Mesh](/images/2023-01-06-data-mesh-intro/mesh.jpg)

# **Introduction**

Much have been said and written about Data Mesh as it is an exciting concept that is still maturing and that has generated a lot of enthusiasm with data practitioners. The term Data Mesh was first coined by Zhamak Dhegani in 2019 in the blog post [How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh](https://martinfowler.com/articles/data-monolith-to-mesh.html), refined later on a second blog post, [Data Mesh Principles and Logical Architecture](https://martinfowler.com/articles/data-mesh-principles.html) and afterwards Zhamak released the [Data Mesh book](https://www.oreilly.com/library/view/data-mesh/9781492092384/), and excellent read that is recommended for any data practitioner.

Here on this post I assume you are familiar with the Data Mesh concept and theory; if not, the sources above are the golden sources to familiarise yourself with it.

#### **How and why did we got here?**

The Data Mesh concept relies on the fact that previous architectural styles and approaches have failed because they leverage a centralised approach, where IT centralises technology, skills, ownership, that created a bottleneck in delivering value derived from data to consumers.

![Data Architecture Journey](/images/2023-01-06-data-mesh-intro/data-architecture-journey.jpg)

The image above depicts the different data architecture approaches that historically have been used:

1. **Data Warehouse Era** - Initially when Data Warehouses were designed the ultimate goal was to support a demand of business requirements that was perfectly met by the supply of data the company acquired and generated.
2. **Data Warehouse Era** - Reality of this era was that the match between demand and supply of data was never met as demand outpaced the supply of data and the speed of which the central IT could deliver releases and features to business users.
3. **Data Lake Era** -  Circa 2010 Data Lakes became quite popular as they promised to democratize data, taking advantage of the "data deluge" that increasingly companies were facing and allowing data consumers to take advantage of that data with increased agility compared to what they could get from the Data Warehouse. On most case Data Lakes often complemented the Data Warehouse rather than replace it.
4. **Self Service Era** - Despite the promise of the data democratisation of the Data Lake, due to the centralisation of technology, skills, ownership, that was adopted even for Data Lakes, and also due to Data Lakes being more difficult to manage and use, the majority of the Lines of Business inside the organisations turned to self service tools and technologies that promised the agility and delivery of value the business demanded. Wide adoption of self service technology was often without the IT team input and typically it created ungoverned data silos, often creating severe data quality issues. 
5. **Data Mesh Era** - We are currently on the Data Mesh era, where data practitioners look into this new concept as a way to once again, have a balance of business demand and supply of data, removing the bottlenecks of a centralised IT by decentralising technology, skills and ownership.

#### **Data Mesh vs Data Warehouses/Lakes/Lakehouses**

The Data Mesh promise is that, 1) leveraging domain ownership, 2) treat data as products, 3) leverage a self serve data platform and 4) enforce a federated computational governance, optimal exploration and use of data can be achieved, something previous architectural approaches have failed to deliver.

My opinion and empirical observation from years of doing systems architecture is that often architectures and systems might fail to deliver on their promises but seldom technology is the only or the most influential culprit. Data Warehouses, Data Lakes and Data Lakehouses if architected on a pragmatical way, leveraging best practices, leveraging the most appropriate technology for the use case and if deployed and operated by a team that has the correct skill set will be successful and can even be part of a successful Data Mesh approach and architecture.

To my eyes the question is not deploying a Data Mesh or a DW/Lake/Lakehouse. It is rather deploying a Data Mesh and a DW/Lake/Lakehouse as often the backbone of the Data Mesh is a DW/Lake/Lakehouse architecture that supports the several data domains.

#### **Data Platform Decentralisation**

Decentralisation of domain ownership doesn't necessarily mean a complete decentralisation of the data infrastructure. Keep in mind that modern cloud data infrastructure and platforms are designed with modularity in mind and they are the complete opposite of a monolith and as such offer the prefect technology capabilities to address a Data Mesh that needs a complete decentralised data platform or one that consolidates the different domains on a smaller set of cloud services providing flexibility, isolation, agility and cost efficiency.

Don't get me wrong, decentralisation of the data platform is a consideration when deploying a Data Mesh, but that design decision needs to be assessed as it involves a trade off between agility, cost, operational effort, governance, performance, security and compliance. 

Careful thought need to be done so that deploying a Data Mesh for a particular case solves challenges instead of creating unnecessary challenges.

Decentralisation of the data platform itself should be done as needed and if needed and should have a rationale behind it and associated business and/or technical benefits. Below are some examples, not exhaustive, for which decentralisation of the platform might make sense:

1. Large organization that operates in different geographies and segregates the data platform by geography leveraging a different tenant for each geography
2. Data domains that curate and provide data products that are of high volume (millions to billions of records), that have stringent SLAs and that if not isolated on a different instance (of a cloud DW or a Spark Cluster as examples) would dramatically affect the other domains to serve their data products
3.  Organisation that wants to track cloud operating costs for each domain, that want to make the domains accountable for their costs and hence segregate per domain all cloud services and resources that have associated cost

#### **Data Products**

To me the most interesting concept that Data Mesh brings is enticing everyone to think about Data Products curated within a bounded context and a define data domain that addresses that bounded context. This is a powerful concept that can be applied to Data Meshes as well as to modern cloud Data Warehouses, Lakes and Lakehouses. I would even go further and say that this should be the standard approach to producing de delivering value with data regardless of the architecture approach and deployment that is chosen as it creates accountability, increases quality and improves business outcomes as a consequence.

#### **Federated Computational Governance**

Governing a Data Mesh and enforcing access management and data security are crucial to deploy and operate a Data Mesh. Decentralising ownership if not accompanied with proper security guard rails can lead to 1) data exfiltration and potential data breaches or 2) creation of locked down data silos. Both will hamper seriously any Data Mesh initiative and hence governance should be top of mind when designing a Data Mesh architecture.

Doing Data Mesh at scale and having several domains producing data products, having dozens, hundreds or even thousands of data consumers means that automation is crucial to 1) grant access to data products, 2) to track data products usage and 3) to audit access to those data products. 

Cloud is built with fine grained security and access control for all APIs and since in cloud everything is an API for which invocation can be automated, data mesh and cloud are the perfect combination.

#### **Data Platform Architectural Styles to support a Data Mesh**

Let me state the obvious, Data Mesh is an approach, not a technology, not a product and also not an architecture. It advocates an approach leveraging domain and product thinking but doesn't enforce a specific data architecture and in my opinion you can build, deploy and run a data mesh leveraging several modern cloud data architectures.

Modern cloud data architectures leverage a set of services, that address several of the capabilities needed for a data mesh (from data pipelines, to data storage, to data serving, ...), expose those services features via console/API/SDK/automation and all them have fine grained IAM controls so it is easy to 1) segregate data domains, 2) allow the flexibility for those domains to leverage the services and capabilities they need to produce data products and 3) have the governance and observability capabilities needed to run a secure and trustworthy data mesh.

The table below compares the most common data architectures in cloud (data warehouse, data lake, data lakehouse) and a fully decentralised data mesh platform deployed across different tenants or even clouds.

Item | Data Warehouse| Data Lake | Data Lakehouse | Distributed Data Mesh
:------ | :----- | :---- | :------ | :------ | :------
Data Platform | centralised or decentralised | centralised or decentralised | centralised or decentralised | decentralised
Data Domain Driven | supported | supported | supported | supported
Multi tenant/Multi domain | supported | supported | supported | supported
Governance Effort | lower | lower | medium | higher
Polyglot support | high | high | high | higher
Single/Multi Region | single | single | single | multi region / multi cloud

In summary a data mesh is possible to be deployed and operated on top of a data warehouse, lake, lakehouse or even on a distributed data platform that can be multi tenant or multi cloud. 

Note that deploying, governing and operating a data mesh on a data warehouse, data lake or lakehouse is less complex and more manageable than a complete decentralised data mesh so the architecture style chosen should be carefully defined according to the needs of each specific organization. 

In my opinion a lakehouse architecture is one of the best architectures to deploy and operate simple to complex data meshes that deliver business benefits to end users. It provides all the capabilities of a modern cloud data warehouse, augmented with all the capabilities of a lake, that can store and process any data at scale. 

Note that for more complex organisations, for instance operating on different geographies, a decentralised approach is most likely the optimal solution but even on those cases the lakehouse toolkit can be leveraged to support all domains on each and every node on that decentralised data mesh.

My advice, use common sense when designing a data mesh approach and the underlying data platform, and design a fit for purpose data platform without creating unnecessary complexity and thus compromises in cost, performance, governance and security.

# **Practical Data Mesh Deployment Example**

On this section I will focus on describing a Data Mesh deployment in [OCI (Oracle Cloud Infrastructure)](https://www.oracle.com/cloud/) leveraging a practical approach.

The data platform used on this example is built on top of a lakehouse deployed on OCI, depicted below and explained on [Oracle Architecture Center](https://docs.oracle.com/en/solutions/oci-curated-analysis/index.html#GUID-7FF7A024-5EB0-414B-A1A5-4718929DC7F2). 

![OCI Lakehouse Reference Architecture](/images/2023-01-06-data-mesh-intro/cloud-data-lake-house-architecture.png)

I suggest that you become familiar with it as it provides the key components to build a data mesh in general, including the one described on this blog post. I also assume you are familiar with a lakehouse in general and ideally you're also familiar with the OCI Lakehouse Reference Architecture and OCI.

#### **Personas**

A Data Mesh should support several personas that deploy, operate, use and manage it. Typical those personas fall into these categories:

1. **Data Product Owner** - this is one of the key roles since it represents the ownership and accountability of the data product that is produced in the domain and it is the role that understands data consumer needs, how a data product might address those needs, envisions and builds that data product leveraging the domain subject matter experts, publishes, secures, govern and evolves the data product. Depending on how large is the domain these tasks might be done by other roles but they are coordinated by the Data Product Owner.
2. **Data Product Consumer** - self discover data products from the mesh catalog, the catalog that exposes data products to consumers, subscribes to the data products and uses them; one key task that a consumer ideally does is provide feedback to the data product owners so that there is a continuous improvement of the data products based on its real  life usage done by consumers.
3. **Chief Data Officer** - understands and has visibility of all data products available on the data mesh, it governs and enforces common rules that all domains must adhere, namely in terms of data classification and security, it understands data products interdependencies and needs to have auditing and forensic analysis capabilities

The three roles mentioned above will be used throughout this examples. Note that on a more complex environment other roles will exist that will complement these, such as functional and technical subject matter experts per domain that work in tandem with the data product owner. It is not the focus of this blog post to exhaustively document all the roles that build, govern and operate a data mesh.

#### **Domains and Segregation**

Identifying Data Domains is a key process to be successful in implementing a domain driven design approach. 

From a functional perspective they are typically aligned with business domains. From a technical perspective they should be isolated so that the data domain team has the flexibility to deploy and manage their data platform and hence have the agility to leverage that platform to build, deploy, operate and govern data products.

In OCI we could leverage several approaches to isolate the different domains, each have their advantages and disadvantages and there isn't a silver bullet that addresses all scenarios.

**Compartment Segregation**

![Compartment Isolation](/images/2023-01-06-data-mesh-intro/isolation-compartment.jpg)

A compartment is a construct that allows cloud resources segregation in OCI. Below it is the definition of compartment.

> A collection of related resources. Compartments are a fundamental component of Oracle Cloud Infrastructure for organizing and isolating your cloud resources. You use them to clearly separate resources for the purposes of measuring usage and billing, access (through the use of policies), and isolation (separating the resources for one project or business unit from another).

Segregating domains by compartments is quite natural in OCI as that is a standard practice to isolate resources used by teams, departments and also on this case data domains. 

In this case each domain will have a compartment which holds the OCI resources they need in the domain and for which they can fully manage.

This type of isolation is easy to configure but for several scenarios it might not offer the level of isolation needed.

**Compartment and Networking Segregation**

![Compartment Isolation](/images/2023-01-06-data-mesh-intro/isolation-compartment-networking.jpg)

Building upon compartment segregation, if network segregation is also used in conjunction, then the level of isolation is increased and the flexibility that the domain SMEs have to deploy and operate cloud resources needed to build and deliver data products is also increased as a consequence.   

**Tenant Segregation**

![Compartment Isolation](/images/2023-01-06-data-mesh-intro/isolation-tenant.jpg)

**Approaches comparison**

Item | Compartments | Compartments & Networking | Tenants
:------ | :----- | :---- | :------ | :------
Isolation |  |  | 
Data Domain Driven |  |  | 
Maintenance Effort |  |  | 
Governance Effort |  |  | 
On Boarding |  |  | 
Observability |  |  | 
Auditing |  |  | 

# **Implementation Example**

#### **Use Case**

#### **Cloud Topology**

# **Summary**